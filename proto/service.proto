syntax = "proto3";

package simulatorproto;

import "proto/encounter_config.proto";
import "proto/player_config.proto";
import "proto/policy_config.proto";

message Distribution {
  int32 n = 1;
  double mean = 2;
  double stddev = 3;
}

message ParameterConfig {
  // Hard minimum number of iterations to perform.
  // Reasonable default: 100
  int32 min_iterations = 1;

  // Approximate maximum number of iterations to perform.
  // Not a hard max, because threads are allowed to race a bit to finish.
  // Reasonable default: 10,000
  int32 max_iterations = 2;

  // We'll halt a simulation early if the error drops below this threshold.
  // Reasonable default: 0.01
  double target_error = 3;

  // If debug_mode is set, we produce lots of output.
  // We also run only one iteration.
  bool debug = 4;
}
message SimulationConfig {
  // `parameter_config` controls constants for the simulation engine.
  ParameterConfig parameter_config = 1;

  // `encounter_config` contains all parameters pertaining to the fight script.
  EncounterConfig encounter_config = 4;

  // `player_config` contains the gearset we're evaluating our policy on,
  // as well as our current talent setup.
  PlayerConfig player_config = 5;

  // `policy` represents the current policy we want our simulator to evaluate.
  // The policy might come in as a deterministic APL or a deep learning model.
  PolicyConfig policy_config = 6;
}

message SimulationResult {
  Distribution dps_distribution = 1;
  string metadata = 2;
}

message SimulationRequest {
  SimulationConfig config = 1;
}

message SimulationResponse {
  SimulationResult result = 1;
}

service SimulationService {
  rpc ConductSimulation(SimulationRequest) returns (SimulationResponse) {
  }
}
