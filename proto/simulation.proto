syntax = "proto3";

package simulate;

import "proto/encounter_config.proto";
import "proto/player_config.proto";
import "proto/policy.proto";

message Distribution {
  double mean = 1;
  double variance = 2;
}

message SimulationConfig {
  // This represents the maximum number of iterations we're willing to perform.
  // Reasonable default: 10,000
  int32 max_iterations = 1;

  // We'll halt a simulation early if the error drops below this threshold.
  // Reasonable default: 0.01
  double target_error = 2;

  // The latency distribution for world lag (units for mean are milliseconds,
  // despite being of type double)
  Distribution world_lag = 3;

  // The latency distriution for how well we react to changes in state.
  Distribution brain_lag = 4;

  // `encounter_config` contains all parameters pertaining to the fight script.
  // This proto also holds duration information (how long the fight is).
  EncounterConfig encounter_config = 5;

  // `player_config` contains the gearset we're evaluating our policy on, as
  // well as our current talent setup.
  PlayerConfig player_config = 6;

  // `policy` represents the current policy we want our simulator to evaluate.
  // The policy might come in as a deterministic APL or a deep learning model.
  Policy policy = 7;
}

message SimulationResult {
  Distribution dps_distribution = 1;
  string metadata = 2;
}
